\[
   \def\bold#1{\boldsymbol{ #1} }
\]
<div>
    <h2>Overview</h2>
    <p>
        This assignment marks the culmination of the previous sequence of
        homeworks. You will get to build a path tracer that accounts for global
        illumination to render realistic images featuring interreflection
        between objects with advanced reflectance models that account for
        surface roughness. Your implementation will rely on two distinct
        sampling strategies and combine them using <em>multiple importance
        sampling</em> (MIS) to give preference to each strategy where it
        performs best.
    </p>
    <p>
        As usual, begin by importing the latest base code updates into your
        repository by running
    </p>
<pre class="prettyprint lang-bash">
$ git pull upstream master
</pre>
    <p>
        If there were any concurrent changes to the same file, you
        may have to perform a <em>merge</em> (see the git tutorials under
        "Preliminaries" for more information).
    </p>

	<h3>Part 1: Microfacet BRDF <em>(30 points)</em></h3>
    <div class="row" style="margin: 30px">
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/ajax-smooth.jpg"><img src="images/ajax-smooth.jpg"/></a>
                <div class="caption">
                    The Ajax bust rendered with a relatively smooth (\(\alpha=0.08\)) microfacet BRDF.
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/ajax-rough.jpg"><img src="images/ajax-rough.jpg"/></a>
                <div class="caption">
                    The Ajax bust rendered with a relatively rough (\(\alpha=0.28\)) microfacet BRDF.
                </div>
            </div>
        </div>
    </div>
    <p>
    In this part we will extend the rudimentary implementation in <tt>microfacet.cpp</tt> into a full-fledge reflectance model based on the <em>microfacet theory</em> presented in class. This utilizes the sampling techniques for the Beckmann distribution that you implemented in a previous assignment. The process is split into two parts:
   </p>
    <h4>Part 1.1: Evaluating the Microfacet BRDF (15 pts)</h4>
    <p>
    The Microfacet BRDF in <code>src/microfacet.cpp</code> will be used to simulate plastic-like materials. It consists of a linear blend between a diffuse BRDF (to simulate a potentially colored reflection from the interior of the material) and a rough dielectric microfacet BRDF (to simulate a non-colored specular reflection from the rough boundary). Implement <code>Microfacet::eval()</code> which evaluates the described microfacet BRDF for a given pair of directions in the local shading coordinate frame:
        \[
            f_r(\bold{\omega_i},\bold{\omega_o}) = \frac{k_d}{\pi} + {k_s} \frac{D(\bold{\omega_{h}})~
            F\left({(\bold{\omega_h} \cdot \bold{\omega_i})}, \eta_{e},\eta_{i}\right)~
            G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}})}{4 \cos{\theta_i} \cos{\theta_o}\cos\theta_h}, ~~
            \bold{\omega_{h}} = \frac{\left(\bold{\omega_i} + \bold{\omega_o}\right)}{\left|\left|\bold{\omega_i} + \bold{\omega_o}\right|\right|_2}
        \]
        Here, \(k_d \in [0,1]^3\) is the RGB diffuse reflection coefficient, \(k_s = 1 - \max(k_d)\), \(F\) is the Fresnel reflection coefficient (check <tt>common.cpp</tt>), \(\eta_e\) is the exterior index of refraction and \(\eta_i\) is the interior index of refraction.
        The various \(\cos\theta_k\) cosine factors relate to the angle that the corresponding direction \(\bold{\omega_k}\) makes with the Z axis in the local coordinate system.
        The shadowing term uses the rational function approximation defined in class:
        \[
            G(\bold{\omega_i},\bold{\omega_o},\bold{\omega_{h}}) = G_1(\bold{\omega_i},\bold{\omega_{h}})~G_1(\bold{\omega_o},\bold{\omega_{h}}),
        \]

        \[
            G_1(\bold{\omega_v},\bold{\omega_h}) = \chi^+\left(\frac{\bold{\omega_v}\cdot\bold{\omega_h}}{\bold{\omega_v}\cdot\bold{n}}\right)
            \begin{cases}
                \frac{3.535b+2.181b^2}{1+2.276b+2.577b^2}, & b \lt 1.6, \\
                1, 										  & \text{otherwise},
            \end{cases} \\

            b = (\alpha \tan{\theta_v})^{-1}, ~~

            \chi^+(c) =
            \begin{cases}
                1, & c > 0, \\
                0, & c \le 0,
            \end{cases} \\

        \]
        where \(\theta_v\) is the angle between the surface normal \(\bold{n}\)
        and the \(\omega_v\) argument of \(G_1\).
    </p>
    <p>
        Recall the <em>Beckmann</em> distribution from Assignment 3, which is used to model the probability density of normals on a random rough surface:
        \[
        D(\theta, \phi) = \underbrace{\frac{1}{2\pi}}_{\text{azimuthal part}}\ \cdot\ \underbrace{\frac{2 e^{\frac{-\tan^2{\theta}}{\alpha^2}}}{\alpha^2 \cos^3 \theta}}_{\text{longitudinal part}}\!\!\!.
        \]
        Note that this definition is slightly different from the one shown in class: the density includes an extra cosine factor for normalization purposes so that it integrates to one over the hemisphere.
    </p>

    <h4>Part 1.2: Sampling the Microfacet BRDF (15 pts)</h4>
    <p>
        In this part you will generate samples according to the following density function:
        \[
            k_s ~ D(\omega_h) ~ J_h + (1-k_s) \frac{\cos{\theta_o}}{\pi}
        \]
        where \(\omega_o\) is sampled and \(J_h = (4 (\omega_h \cdot \omega_o))^{-1}\)
        is the Jacobian of the half direction mapping discussed in class.

        This can be done using the following sequence of steps:
    </p>
    <ol>
        <li>Decide between a diffuse or a specular reflection by comparing a uniform variate \(\xi_1\) against \(k_s\)</li>
        <li>Scale and potentially offset the uniform variate \(\xi_1\) so that it can be reused for a later sampling step (see <tt>DiscretePDF::sampleReuse</tt>)</li>
        <li>In the diffuse case, generate a cosine-weighted direction on the sphere following the approach in <tt>src/diffuse.cpp</tt></li>
        <li>In the specular case:
            <ol>
                <li>Sample a normal from the Beckmann distribution using <code>Warp::squareToBeckmann</code> that you previously implemented in Assignment 3.</li>
                <li>Reflect the incident direction using this normal to generate an outgoing direction.</li>
            </ol>
        </li>
    </ol>
    <p>
        Note that you will need to implement both <code>Microfacet::sample()</code> and <code>Microfacet::pdf()</code> to be able to run the following tests.
    </p>

    <h4>Validation</h4>
    <p>To obtain the full set of points for the previous exercises, you will
        need to validate the correctness of your code.</p>
    <ol>
        <li>Pass the following statistical tests in <code>scenes/pa5/tests</code>:</li>
            <ul>
                <li><tt>chi2test-microfacet.xml</tt></li>
                <li><tt>ttest-microfacet.xml</tt></li>
            </ul>
            <p>
            The tests are also part of the continous integration environment, so note that your build will "fail" as long as not all tests pass.
            </p>
            <p>
                The <tt>warptest</tt>GUI also contains
                a \(\chi^2\) test for the BRDF model, but this is just to facilitate debugging and
                visualization; the XML files are the real validation benchmark.
                Mention in your report if running these tests produces any errors.
            </p>

        <br>
        <li>Use your <tt>whitted</tt> integrator from the previous assignment to render a microfacet Ajax bust and ensure that you can match our references for the following scenes in <code>scenes/pa5</code>:</li>
            <ul>
                <li><tt>ajax/ajax-smooth.xml</tt> (<a href="references/ajax-smooth.exr">Reference</a>)</li>
                <li><tt>ajax/ajax-rough.xml</tt> (<a href="references/ajax-rough.exr">Reference</a>)</li>
            </ul>
    </ol>
    <p>
    <b>Make sure to discuss the design choices and relevant technical information about your implementation in the report and include comparisons against our reference renderings.</b>
    </p>

    <h3>Part 2: <tt>path_mats</tt> Brute force path tracer <em>(15 points)</em></h3>
    <div class="row" style="margin: 30px">
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/cbox_mats.png"><img src="images/cbox_mats.png"/></a>
                <div class="caption">
                    The Cornell box rendered using the brute-force path tracer. Note
                    the indirect illumination on the ceiling and the light-focusing
                    behavior of the sphere.
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/veach_mats.png"><img src="images/veach_mats.png"/></a>
                <div class="caption">
                    The Veach material test scene, rendered with brute-force path tracing.
                </div>
            </div>
        </div>
    </div>

    <p>
        In the lecture you saw that there are multiple ways to solve the rendering equation and the emitter sampling strategy implemented in Assignment 4 was just one possibility. A much simpler (but also more naive) version of path tracing relies on hitting light sources in the scene by pure chance instead of explicitly sampling points on them during integration.
        In other words, you exchange emitter sampling with sampling outgoing directions according to the BSDF.
        <br/>
        Furthermore, we will extend the Whitted-style algorithm into a full path tracer that accounts for indirect illumination as well.
        The main differences from <code>src/whitted.cpp</code> are:
        <ol>
            <li>We (temporarily) removed emitter sampling.</li>
            <li>Paths should now continue not only after specular surface interactions, but for all interactions.</li>
        </ol>
    </p>

    <p>
        Create a new "material sampling" (mats) path tracer named
        <code>src/path_mats.cpp</code> that does exactly this. Note that you
        should use <code>BSDF::sample()</code> to generate new outoing
        directions at each scattering event. This outgoing direction is used to
        estimate the indirect illumination component. <b>We recommend that you
        implement all integrators in this homework using an "iterative" approach
        with a for-loop instead of recursion that you might have used for the
        Whitted-style integrator. This is more efficient and will also be
        considerably easier to debug.</b>
    </p>

    <p>
        <strong>Note</strong>: to match the reference renders exactly, you will
        need to use the following Russian Roulette heuristic for path
        termination:<br/>
        <pre class="prettyprint">
continuation probability = min(maximum component of the throughput * eta^2, 0.99)</pre>
        where <tt>eta</tt> is the product of all \(\eta\) terms encountered
        along the path, starting with <tt>eta = 1.f</tt>. Additionally, we
        recommend to only start doing Russian Roulette after at least three
        bounces in order to avoid terminating very short paths which would lead
        to a lot of variance.
    </p>


    <h4>Validation</h4>
    <ol>
        <li>Render the following scenes in <code>scenes/pa5</code>:</li>
            <ul>
                <li><tt>cbox/cbox_mats.xml</tt> (<a href="references/cbox_mats.exr">Reference</a>)</li>
                <li><tt>veach_mi/veach_mats.xml</tt> (<a href="references/veach_mats.exr">Reference</a>)</li>
                <li><tt>table/table_mats.xml</tt> (<a href="references/table_mats.exr">Reference</a>)</li>
            </ul>
        <br>
        <li>Pass the following statistical tests in <code>scenes/pa5/tests</code>:</li>
            <ul>
                <li><tt>test-direct.xml</tt> (Tests 6-10)</li>
                <li><tt>test-furnace.xml</tt> (Tests 3-4)</li>
            </ul>
            <p>
            The tests are also part of the continous integration environment, so note that your build will "fail" as long as not all tests pass.
            </p>
    </ol>
    <b>Make sure that you include comparisons against our reference renderings
    and screenshots of statistical tests in the report. This will be graded.</b>
    </p>

    <h3>Part 3: <tt>path_ems</tt> Path tracer with next event estimation <em>(25 points)</em></h3>
    <div class="row" style="margin: 30px">
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/cbox-gi.jpg"><img src="images/cbox-gi.jpg"/></a>
                <div class="caption">
                    The Cornell box rendered using the Next Event Estimation path tracer.
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/veach_path_simple.jpg"><img src="images/veach_path_simple.jpg"/></a>
                <div class="caption">
                    The Veach material test scene. Notice the significant variance
                    for the top bar (shiniest) reflecting the largest light source.
                    The path tracer with multiple importance sampling will address this issue.
                </div>
            </div>
        </div>
    </div>
    <p>
        In part 2, you implemented a brute-force path tracer. As you may have noticed, it suffers
        from high variance due to its naive sampling strategy. We'll now implement
        an "emitter sampling" (ems) path tracer named <code>src/path_ems.cpp</code> (this
        corresponds to the "Path Tracing with explicit shadow rays" discussed
        during the lecture). The last part of the assignment will involve adding <em>multiple
        importance sampling</em> (MIS) to create a full-featured path tracer that combines both
        sampling strategies to reduce variance.<br/>
        Starting from <tt>path_mats</tt>, simply add back emitter sampling while taking care of the
        "double counting" problem discussed in the lecture.
    </p>

    <p>
        <strong>Note</strong>: Different (correct) implementations of emitter sampling will lead to potentially very different noise patterns in the test scenes. If you want to match the reference renders exactly, you will need to (in each iteration) <b>1)</b> Pick one light source uniformly at random, and <b>2)</b> Sample one point on the associated mesh uniformly over its surface area.<br/>
    </p>

    <h4>Validation</h4>
    <ol>
        <li>Render the following scenes in <code>scenes/pa5</code>:</li>
            <ul>
                <li><tt>cbox/cbox_ems.xml</tt> (<a href="references/cbox_ems.exr">Reference</a>)</li>
                <li><tt>veach_mi/veach_ems.xml</tt> (<a href="references/veach_ems.exr">Reference</a>)</li>
                <li><tt>table/table_ems.xml</tt> (<a href="references/table_ems.exr">Reference</a>)</li>
            </ul>

            <p>
            The first scene only uses diffuse and specular materials and can be
            used to test your path tracer if you didn't do part 1 of this assignment
            yet. The latter two assume that the microfacet model BRDF is ready.
            </p>
        <br>
        <li>Pass the following statistical tests in <code>scenes/pa5/tests</code>:</li>
            <ul>
                <li><tt>test-direct.xml</tt> (Tests 1-5)</li>
                <li><tt>test-furnace.xml</tt> (Tests 1-2)</li>
            </ul>
            <p>
            The tests are also part of the continous integration environment, so note that your build will "fail" as long as not all tests pass.
            </p>
    </ol>
    <p>
        <b>Make sure to discuss the design choices and relevant technical information about your implementation in the report and include comparisons against our reference renderings.</b>
    </p>

    <h3>Part 4: <tt>path_mis</tt> Path tracer with Multiple Importance Sampling <em>(30 points)</em></h3>
    <div class="row" style="margin: 30px">
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/table_path.jpg"><img src="images/table_path.jpg"/></a>
                <div class="caption">
                    Table scene featuring a water-filled glass and a bowl modeled using
                    a microfacet material.
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/veach_path.jpg"><img src="images/veach_path.jpg"/></a>
                <div class="caption">
                    The Veach material test scene, now rendered using MIS.
                </div>
            </div>
        </div>
    </div>
    <p>
        For this last part you will combine both sampling strategies from the previous tasks into one integrator <code>src/path_mis.cpp</code> that has <em>multiple importance sampling</em>:
    </p>
    <ol>
        <li>When generating a sample on a light source, determine the density of this
            sampling strategy. Also compute the density (using <code>BSDF::pdf()</code>) with which the BRDF sampling strategy <em>would hypothetically</em> have sampled the same direction.</li>
        <li> Weight the contribution of the light source sample using the following formula
            known as the <em>balance heuristic</em>:
            \[
            w_\mathrm{Light}(p_\mathrm{Light}, p_\mathrm{BRDF}) = \frac{p_\mathrm{Light}}{p_\mathrm{Light} + p_\mathrm{BRDF}}.
            \]
            Remember that this only makes sense if both probabilities are expressed in
            the same <em>measure</em> (i.e. with respect to solid angles or unit area). This
            means that you will have convert one of them to the measure of the other (which one doesn't matter).
        </li>
        <li> When generating a BRDF sample (which would normally only be used to estimate
            the indirect illumination component), check if it hits a light source.
            In this case, also use this sample to estimate the <em>direct</em> illumination
            component at the current vertex.
        </li>
        <li>
            Once more, estimate the probability with which light source sampling <em>would hypothetically</em> have sampled this point, and weight the contribution of the sample using the balance heuristic:
            \[
            w_\mathrm{BRDF}(p_\mathrm{Light}, p_\mathrm{BRDF}) = \frac{p_\mathrm{BRDF}}{p_\mathrm{Light} + p_\mathrm{BRDF}}.
            \]
            Note the changed numerator in the above expression.
        </li>
    </ol>

    <h4>Validation</h4>
    <ol>
        <li>Render the following scenes in <code>scenes/pa5</code>:</li>
            <ul>
                <li><tt>cbox/cbox_mis.xml</tt> (<a href="references/cbox_mis.exr">Reference</a>)</li>
                <li><tt>veach_mi/veach_mis.xml</tt> (<a href="references/veach_mis.exr">Reference</a>)</li>
                <li><tt>table/table_mis.xml</tt> (<a href="references/table_mis.exr">Reference</a>)</li>
            </ul>
        <br>
        <li>Pass the following statistical tests in <code>scenes/pa5/tests</code>:</li>
            <ul>
                <li><tt>test-direct.xml</tt> (Tests 11-15)</li>
                <li><tt>test-furnace.xml</tt> (Tests 5-6)</li>
            </ul>
            <p>
            The tests are also part of the continous integration environment, so note that your build will "fail" as long as not all tests pass.
            </p>
    </ol>
    <b>Make sure to discuss the design choices and relevant technical information about your implementation in the report and include comparisons against our reference renderings.</b>
    </p>


    <h3>Artist Points: Interesting scene (5 points)</h3>
    <div class="alert alert-info" role="alert"><b>Disclaimer</b>: Artist points are bonus tasks where you get the opportunity to showcase your own renderings created with your implemented algorithms. They are added to the final score.
    </div>
    <p>
        Build your own artistically appealing scene and include a rendering of
        it in your report. Use any of the implemented integrators so far - or
        build something entirely new! Be creative, your renderings may be posted
        in a gallery on the course website, with your permission. This is a good
        exercise to get some practice putting together a scene by yourself. This
        skill will be very useful for creating your scene for the final project.
    </p>
    <p>
        We recommend to use the 3D modeling tool <a href="https://www.blender.org/">Blender</a>. It can be used to arrange models or to create your own. Feel free to use existing models from websites such as <a href="https://www.blendswap.com/">Blendswap</a>. We provide a (rudimentary) Blender plugin (<code>ext/plugin</code>) that can help with some of the steps involved with exporting a scene to the Nori description language.
    </p>
    <p>
        Please include a short section in the report with your render and credits to any 3D models you used. The artistic characteristics will be graded very leniently :)
    </p>

	<h3> Hacker Points: refraction through rough dielectrics<em> (20 points)</em></h3>
<div class="alert alert-info" role="alert"><b>Disclaimer</b>: Hacker points are “underpriced” bonus points
for the daring few. Sometimes you might be required to implement something that was not taught in class and
you might have to do some research and creative thinking. Hacker Points are awarded only to students who
implemented all of the remaining assignment, and they are added to the final score.
</div>
    <div class="row" style="margin: 30px">
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/ajax-rdiel1.jpg"><img src="images/ajax-rdiel1.jpg"/></a>
                <div class="caption">
                    Rendering of the Ajax bust with a slightly rough refractive material.
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="thumbnail" style="margin: 10px">
                <a class="fancybox" href="images/ajax-rdiel2.jpg"><img src="images/ajax-rdiel2.jpg"/></a>
                <div class="caption">
                    Rendering of the Ajax bust with a <em>very</em> rough refractive material.
                </div>
            </div>
        </div>
    </div>

	<p>
        For this part your task is to extend the rough dielectric BRDF into a
        complete <em>BSDF</em> that also accounts for refraction. You will also
        want to remove the diffuse component as well as the \(k_d\) parameter.
        Begin by reading the paper <em><a href="https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.html">Microfacet Models for Refraction through Rough Surfaces</a></em> by
         Bruce Walter, Stephen R. Marschner, Hongsong Li, and Kenneth E.
         Torrance.
    </p>
    <p>
        To support rough refraction, you implementation will need to randomly
        choose between the reflection and the refraction component based on the
        Fresnel coefficient. Follow the instructions in the paper by Walter et
        al. to add the latter case based on the generalized half-direction
        vector for refraction.
    </p>

	<h4> What to include in your report </h4>
	<p>
		<ul>
            <li> A discussion of how you choose to implement the Walter et al. paper in Nori. </li>
            <li> At least two refractive renderings of the Ajax scene with different roughness values.</li>
            <li> Results of Chi^2 tests, which demonstrate that your sampling technique works correctly.</li>
		</ul>
	</p>
</div>
